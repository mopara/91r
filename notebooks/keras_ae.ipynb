{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(32, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.3605 - val_loss: 0.2652\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.2579 - val_loss: 0.2517\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.2452 - val_loss: 0.2393\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.2351 - val_loss: 0.2278\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.2223 - val_loss: 0.2118\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.2027 - val_loss: 0.1958\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1874 - val_loss: 0.1812\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.1787 - val_loss: 0.1745\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1729 - val_loss: 0.1698\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1682 - val_loss: 0.1645\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1631 - val_loss: 0.1618\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1583 - val_loss: 0.1546\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1543 - val_loss: 0.1511\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1511 - val_loss: 0.1477\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 4s 75us/step - loss: 0.1483 - val_loss: 0.1440\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.1457 - val_loss: 0.1429\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1438 - val_loss: 0.1439\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1419 - val_loss: 0.1415\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1405 - val_loss: 0.1372\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1389 - val_loss: 0.1366\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1375 - val_loss: 0.1366\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1361 - val_loss: 0.1342\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1347 - val_loss: 0.1333\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1333 - val_loss: 0.1292\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1319 - val_loss: 0.1291\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1307 - val_loss: 0.1283\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1293 - val_loss: 0.1268\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1279 - val_loss: 0.1250\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1266 - val_loss: 0.1237\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1256 - val_loss: 0.1243\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1244 - val_loss: 0.1224\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1233 - val_loss: 0.1223\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1223 - val_loss: 0.1210\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1214 - val_loss: 0.1211\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1204 - val_loss: 0.1195\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1198 - val_loss: 0.1179\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1190 - val_loss: 0.1176\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1183 - val_loss: 0.1175\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1178 - val_loss: 0.1171\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1170 - val_loss: 0.1180\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1165 - val_loss: 0.1171\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1160 - val_loss: 0.1128\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1154 - val_loss: 0.1150\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1151 - val_loss: 0.1130\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1145 - val_loss: 0.1120\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1141 - val_loss: 0.1124\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1135 - val_loss: 0.1118\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1132 - val_loss: 0.1129\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1128 - val_loss: 0.1108\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1124 - val_loss: 0.1107\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 5s 79us/step - loss: 0.1119 - val_loss: 0.1111\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1116 - val_loss: 0.1104\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1112 - val_loss: 0.1111\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1110 - val_loss: 0.1100\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1106 - val_loss: 0.1087\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1103 - val_loss: 0.1098\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.1100 - val_loss: 0.1071\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1095 - val_loss: 0.1080\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1093 - val_loss: 0.1077\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1089 - val_loss: 0.1076\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1086 - val_loss: 0.1058\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1084 - val_loss: 0.1075\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1080 - val_loss: 0.1077\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1078 - val_loss: 0.1060\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1076 - val_loss: 0.1062\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.1072 - val_loss: 0.1074\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.1070 - val_loss: 0.1052\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1067 - val_loss: 0.1067\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1063 - val_loss: 0.1051\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1060 - val_loss: 0.1046\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1058 - val_loss: 0.1063\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1056 - val_loss: 0.1043\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.1053 - val_loss: 0.1048\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1051 - val_loss: 0.1046\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1049 - val_loss: 0.1041\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.1046 - val_loss: 0.1040\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1043 - val_loss: 0.1028\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1041 - val_loss: 0.1020\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1039 - val_loss: 0.1032\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1036 - val_loss: 0.1027\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1034 - val_loss: 0.1042\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1031 - val_loss: 0.1018\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1030 - val_loss: 0.1025\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1029 - val_loss: 0.1037\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1024 - val_loss: 0.1026\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1024 - val_loss: 0.1012\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1022 - val_loss: 0.1011\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1019 - val_loss: 0.1026\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1018 - val_loss: 0.1020\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.1014 - val_loss: 0.1002\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1014 - val_loss: 0.1003\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1012 - val_loss: 0.0999\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1009 - val_loss: 0.1006\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1007 - val_loss: 0.1005\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.1006 - val_loss: 0.1021\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.1004 - val_loss: 0.1001\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1002 - val_loss: 0.0985\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.1000 - val_loss: 0.0990\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0998 - val_loss: 0.0985\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0996 - val_loss: 0.0991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11be53f90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x11bf95990>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfoVAE(nn.Module):\n",
    "  def __init__(self, H, W, C_in, C_h1, C_h2, D_h, D_z):\n",
    "    super(InfoVAE, self).__init__()\n",
    "\n",
    "    self.enc = enc = nn.Sequential(\n",
    "      nn.Conv2d(C_in, C_h1, 4, 2, padding=1), # 28 -> 14\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Conv2d(C_h1, C_h2, 4, 2, padding=1), # 14 -> 7\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      Flatten(),\n",
    "      nn.Linear(C_h2*H/4*W/4, D_h),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(D_h, D_z))\n",
    "    self.dec = dec = nn.Sequential(\n",
    "      nn.Linear(D_z, D_h),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h, C_h2*H/4*W/4),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Reshape(C_h2, H/4, W/4),\n",
    "      nn.ConvTranspose2d(C_h2, C_h1, 4, 2, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.ConvTranspose2d(C_h1, C_in, 4, 2, padding=1),\n",
    "      nn.Sigmoid())\n",
    "    self.opt = optim.Adam(it.chain(enc.parameters(), dec.parameters()))\n",
    "\n",
    "  def preprocess(self, x):\n",
    "    return channels_first(x)\n",
    "\n",
    "  def kernel(self, a, b):\n",
    "    N_a, D = a.size()\n",
    "    N_b = b.size(0)\n",
    "\n",
    "    a = a.unsqueeze(1).expand(N_a, N_b, D)\n",
    "    b = b.unsqueeze(0).expand(N_a, N_b, D)\n",
    "\n",
    "    return a.sub(b).pow_(2).mean(dim=2).div_(D).mul_(-1).exp_()\n",
    "\n",
    "  def mmd_loss(self, y_prd, y):\n",
    "    y_prd_k = self.kernel(y_prd, y_prd)\n",
    "    y_k = self.kernel(y, y)\n",
    "    y_prd_y_k = self.kernel(y_prd, y)\n",
    "\n",
    "    # return y_k.mean() + y_prd_k.mean() - 2*y_prd_y_k.mean()\n",
    "    return y_prd_y_k.mul(-2).add_(y_prd_k).add_(y_k).mean()\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    z = self.enc(x)\n",
    "    y_prd = self.dec(z)\n",
    "\n",
    "    mmd = self.mmd_loss(z, t.randn_like(z))\n",
    "    nll = y_prd.sub(y).pow_(2).mean()\n",
    "\n",
    "    return (y_prd, mmd.add_(nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train.reshape((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channels_first(x):\n",
    "  return x.permute(0, 3, 1, 2) # NHWC -> NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, C = x.size()\n",
    "D = H * W * C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = channels_first(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'Flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ca6f074ac712>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInfoVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-e3e007e3ccb2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, H, W, C_in, C_h1, C_h2, D_h, D_z)\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_h1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_h2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 14 -> 7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC_h2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeakyReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'Flatten' is not defined"
     ]
    }
   ],
   "source": [
    "vae = InfoVAE(H, W, C, 64, 128, 1024, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"quit /Applications/Safari.app/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pstree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x11aa9de50>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.Popen(\"pstree\", stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<open file '<fdopen>', mode 'rb' at 0x118a025d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function read>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stdout.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-4ba87d2c6182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Safari\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "p.stdout.read().index(\"Safari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
