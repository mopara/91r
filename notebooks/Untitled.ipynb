{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "\n",
    "def channels_first(x):\n",
    "  return x.permute(0, 3, 1, 2) # NHWC -> NCHW\n",
    "\n",
    "def flatten(x):\n",
    "  return x.reshape(x.size(0), -1)\n",
    "\n",
    "def sample(model, mean, log_var):\n",
    "  if model.training:\n",
    "    return t.randn_like(log_var).mul_(log_var.mul(0.5).exp_()).add_(mean)\n",
    "  else:\n",
    "    return mean\n",
    "\n",
    "def elbo_loss(y_prd, y, mean, log_var):\n",
    "  bce = f.binary_cross_entropy(y_prd, y, size_average=False)\n",
    "  kld = log_var.add(1).sub_(mean.pow(2)).sub_(log_var.exp()).sum().mul_(-0.5)\n",
    "\n",
    "  return bce.add_(kld)\n",
    "\n",
    "def forward(model, x, y, loss):\n",
    "  mean, log_var = model.enc(x)\n",
    "  y_prd = model.dec(sample(model, mean, log_var))\n",
    "\n",
    "  return (y_prd, loss(y_prd, y, mean, log_var))\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Flatten, self).__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    return flatten(x)\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "  def __init__(self, f, g):\n",
    "    super(Lambda, self).__init__()\n",
    "\n",
    "    self.f = f\n",
    "    self.g = g\n",
    "\n",
    "  def forward(self, x):\n",
    "    return (self.f(x), self.g(x))\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "  def __init__(self, *size):\n",
    "    super(Reshape, self).__init__()\n",
    "\n",
    "    self.size = size\n",
    "\n",
    "  def forward(self, x):\n",
    "    return x.reshape(x.size(0), *self.size)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "  def __init__(self, D_in, D_h, D_z):\n",
    "    super(VAE, self).__init__()\n",
    "\n",
    "    mean_fc = nn.Linear(D_h, D_z)\n",
    "    log_var_fc = nn.Linear(D_h, D_z)\n",
    "\n",
    "    self.enc = enc = nn.Sequential(\n",
    "      nn.Linear(D_in, D_h),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Lambda(mean_fc, log_var_fc))\n",
    "    self.dec = dec = nn.Sequential(\n",
    "      nn.Linear(D_z, D_h),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h, D_in),\n",
    "      nn.Sigmoid())\n",
    "    self.opt = optim.Adam(it.chain(enc.parameters(), mean_fc.parameters(),\n",
    "      log_var_fc.parameters(), dec.parameters()), lr=1e-3)\n",
    "\n",
    "  def preprocess(self, x):\n",
    "    return flatten(x)\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    return forward(self, x, y, elbo_loss)\n",
    "\n",
    "class VAE2(nn.Module):\n",
    "  def __init__(self, D_in, D_h1, D_h2, D_h3, D_z):\n",
    "    super(VAE2, self).__init__()\n",
    "\n",
    "    mean_fc = nn.Linear(D_h3, D_z)\n",
    "    log_var_fc = nn.Linear(D_h3, D_z)\n",
    "\n",
    "    self.enc = enc = nn.Sequential(\n",
    "      nn.Linear(D_in, D_h1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h1, D_h2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h2, D_h3),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Lambda(mean_fc, log_var_fc))\n",
    "    self.dec = dec = nn.Sequential(\n",
    "      nn.Linear(D_z, D_h3),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h3, D_h2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h2, D_h1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h1, D_in),\n",
    "      nn.Sigmoid())\n",
    "    self.opt = optim.Adam(it.chain(enc.parameters(), mean_fc.parameters(),\n",
    "      log_var_fc.parameters(), dec.parameters()), lr=1e-3)\n",
    "\n",
    "  def preprocess(self, x):\n",
    "    return flatten(x)\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    return forward(self, x, y, elbo_loss)\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "  def __init__(self, H, W, C_in, C_h, D_h, D_z):\n",
    "    super(CVAE, self).__init__()\n",
    "\n",
    "    mean_fc = nn.Linear(D_h, D_z)\n",
    "    log_var_fc = nn.Linear(D_h, D_z)\n",
    "\n",
    "    self.enc = enc = nn.Sequential(\n",
    "      nn.ZeroPad2d((0, 1, 0, 1)),\n",
    "      nn.Conv2d(C_in, C_h, 2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.ZeroPad2d((0, W % 2, 0, H % 2)),\n",
    "      nn.Conv2d(C_h, C_h, 2, 2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(C_h, C_h, 3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(C_h, C_h, 3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Flatten(),\n",
    "      nn.Linear(C_h*H/2*W/2, D_h),\n",
    "      Lambda(mean_fc, log_var_fc))\n",
    "    self.dec = dec = nn.Sequential(\n",
    "      nn.Linear(D_z, D_h),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h, C_h*H/2*W/2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Reshape(C_h, H/2, W/2),\n",
    "      nn.ConvTranspose2d(C_h, C_h, 3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.ConvTranspose2d(C_h, C_h, 3, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.ConvTranspose2d(C_h, C_h, 3, 2),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Conv2d(C_h, C_in, 2),\n",
    "      nn.Sigmoid())\n",
    "    self.opt = optim.RMSprop(it.chain(enc.parameters(), mean_fc.parameters(),\n",
    "      log_var_fc.parameters(), dec.parameters()), lr=1e-3, alpha=0.9, eps=1e-7)\n",
    "\n",
    "  def preprocess(self, x):\n",
    "    return channels_first(x)\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    return forward(self, x, y, elbo_loss)\n",
    "\n",
    "class InfoVAE(nn.Module):\n",
    "  def __init__(self, H, W, C_in, C_h1, C_h2, D_h, D_z):\n",
    "    super(InfoVAE, self).__init__()\n",
    "\n",
    "    self.enc = enc = nn.Sequential(\n",
    "      nn.Conv2d(C_in, C_h1, 4, 2, padding=1), # 28 -> 14\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Conv2d(C_h1, C_h2, 4, 2, padding=1), # 14 -> 7\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      Flatten(),\n",
    "      nn.Linear(C_h2*H/4*W/4, D_h),\n",
    "      nn.LeakyReLU(inplace=True),\n",
    "      nn.Linear(D_h, D_z))\n",
    "    self.dec = dec = nn.Sequential(\n",
    "      nn.Linear(D_z, D_h),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.Linear(D_h, C_h2*H/4*W/4),\n",
    "      nn.ReLU(inplace=True),\n",
    "      Reshape(C_h2, H/4, W/4),\n",
    "      nn.ConvTranspose2d(C_h2, C_h1, 4, 2, padding=1),\n",
    "      nn.ReLU(inplace=True),\n",
    "      nn.ConvTranspose2d(C_h1, C_in, 4, 2, padding=1),\n",
    "      nn.Sigmoid())\n",
    "    self.opt = optim.Adam(it.chain(enc.parameters(), dec.parameters()))\n",
    "\n",
    "  def preprocess(self, x):\n",
    "    return channels_first(x)\n",
    "\n",
    "  def kernel(self, a, b):\n",
    "    N_a, D = a.size()\n",
    "    N_b = b.size(0)\n",
    "\n",
    "    a = a.unsqueeze(1).expand(N_a, N_b, D)\n",
    "    b = b.unsqueeze(0).expand(N_a, N_b, D)\n",
    "\n",
    "    return a.sub(b).pow_(2).mean(dim=2).div_(D).mul_(-1).exp_()\n",
    "\n",
    "  def mmd_loss(self, y_prd, y):\n",
    "    y_prd_k = self.kernel(y_prd, y_prd)\n",
    "    y_k = self.kernel(y, y)\n",
    "    y_prd_y_k = self.kernel(y_prd, y)\n",
    "\n",
    "    # return y_k.mean() + y_prd_k.mean() - 2*y_prd_y_k.mean()\n",
    "    return y_prd_y_k.mul(-2).add_(y_prd_k).add_(y_k).mean()\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    z = self.enc(x)\n",
    "    y_prd = self.dec(z)\n",
    "\n",
    "    mmd = self.mmd_loss(z, t.randn_like(z))\n",
    "    nll = y_prd.sub(y).pow_(2).mean()\n",
    "\n",
    "    return (y_prd, mmd.add_(nll))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import struct\n",
    "import torch as t\n",
    "\n",
    "def parse_args():\n",
    "  parser = argparse.ArgumentParser()\n",
    "\n",
    "  parser.add_argument(\"action\", type=str, help=\"either 'mnist' or 'vids'\")\n",
    "  parser.add_argument(\"-i\", nargs=\"+\", type=str, required=True,\n",
    "    help=\"input file names\", metavar=\"FILE\")\n",
    "  parser.add_argument(\"-o\", type=str, required=True,\n",
    "    help=\"destination directory\", metavar=\"DST_DIR\")\n",
    "\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  return (args.action, args.o, args.i)\n",
    "\n",
    "def stem(file_name):\n",
    "  return path.splitext(path.basename(file_name))[0]\n",
    "\n",
    "def save(dst_dir, file_name, arr):\n",
    "  file_name = path.join(dst_dir, stem(file_name))\n",
    "\n",
    "  np.save(file_name, arr)\n",
    "  t.save(t.tensor(arr), file_name+\".pt\")\n",
    "\n",
    "  print \"%s\\tshape: %s\" % (file_name, arr.shape)\n",
    "\n",
    "def mnist(file_names, dst_dir):\n",
    "  for file_name in file_names:\n",
    "    with open(file_name, \"rb\") as file:\n",
    "      # >: big-endian\n",
    "      # H: ushort (2 bytes)\n",
    "      # B: uchar (1 byte)\n",
    "      # I: uint (4 bytes)\n",
    "      zeros, dtype, dims = struct.unpack(\">HBB\", file.read(4))\n",
    "      shape = [struct.unpack(\">I\", file.read(4))[0] for dim in range(dims)]\n",
    "\n",
    "      # mnist input files known to have uint8 dtype\n",
    "      arr = np.frombuffer(file.read(), dtype=np.uint8).reshape(shape)\n",
    "\n",
    "      save(dst_dir, file_name, arr)\n",
    "\n",
    "def vids(file_names, dst_dir):\n",
    "  for file_name in file_names:\n",
    "    vid = cv2.VideoCapture(file_name)\n",
    "\n",
    "    num_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    vid_arr = np.empty((num_frames, height, width, 3), dtype=np.uint8)\n",
    "\n",
    "    for frame_num in xrange(num_frames):\n",
    "      ret, frame = vid.read()\n",
    "\n",
    "      if ret:\n",
    "        vid_arr[frame_num] = frame\n",
    "      else:\n",
    "        print \"error in %s: frame [%d/%d]\" % (file_name, frame_num, num_frames)\n",
    "        break\n",
    "\n",
    "    vid.release()\n",
    "\n",
    "    save(dst_dir, file_name, vid_arr)\n",
    "\n",
    "# ex:\n",
    "# python src/data.py mnist -i mnist/src/*-ubyte -o mnist/\n",
    "# python src/data.py vids -i vids/src/a4.sax.mov -o vids/\n",
    "# python src/data.py vids -i vids/src/e5.practice.mov -o vids/\n",
    "# if __name__ == \"__main__\":\n",
    "#   action, dst_dir, file_names = parse_args()\n",
    "\n",
    "#   {\"mnist\": mnist, \"vids\": vids}[action](file_names, dst_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = t.load(\"../mnist/train-images-idx3-ubyte.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = channels_first(x.unsqueeze(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
